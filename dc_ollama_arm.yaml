services:
  ollama:
    container_name: ollama
    image: ictrektech/ollama_server:arm_latest
    restart: on-failure
    command: ["bash", "/root/ollama_run.sh"]
    stdin_open: true  # 启用标准输入
    tty: true         # 启用伪终端
    environment:
      - MAX_MODEL_LEN=32768
      # - HTTP_PROXY=http://192.168.1.91:7897
      # - HTTPS_PROXY=http://192.168.1.91:7897
    volumes:
      - ${HOME}/.ollama:/root/.ollama
    ports:
      - "22299:11434"
      - "11434:11434"
    networks:
      fastllm:
        ipv4_address: 172.28.1.100

networks:
  fastllm:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.1.0/24
